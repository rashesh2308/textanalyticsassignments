{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "table.dataframe td, table.dataframe th {\n",
       "    border: 1px  black solid !important;\n",
       "  color: black !important;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style type=\"text/css\">\n",
    "table.dataframe td, table.dataframe th {\n",
    "    border: 1px  black solid !important;\n",
    "  color: black !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.core.common import flatten\n",
    "import numpy as np\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "import rapidfuzz\n",
    "from rapidfuzz import process, utils\n",
    "\n",
    "import timeit\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#importing the file\n",
    "dfdashboards = pd.read_csv('microstrategy_and_dashboard.csv')\n",
    "dfmetrics = pd.read_csv('tableau_metric.csv')\n",
    "dfuserquey = pd.read_csv('sample_user_searchs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_datafiles(dashboard , metric):\n",
    "\n",
    "    #converting column values to lowercase\n",
    "    dashboard = dashboard.apply(lambda x: x.astype(str).str.lower())\n",
    "    metric = metric.apply(lambda x: x.astype(str).str.lower())\n",
    "    \n",
    "    #converting global usage to numeric\n",
    "    dashboard.Global_usage = pd.to_numeric(dashboard.Global_usage)\n",
    "    \n",
    "    #splitting caption and descriptors columns \n",
    "    dashboard = dashboard[['dashboards','caption','Global_usage']]\n",
    "    dashboard['metric_names'] = dashboard.caption.str.split('|')\n",
    "    metric['descriptors'] = metric.descriptors.str.split('|')\n",
    "    \n",
    "    #converting metric names and descriptors in each row values to multiple rows\n",
    "\n",
    "    temp1 = dashboard.set_index(['dashboards'])['metric_names'].apply(pd.Series).stack().reset_index().drop('level_1', axis=1).rename(columns={0:'caption'})\n",
    "    temp2 = metric.set_index(['metric_name'])['descriptors'].apply(pd.Series).stack().reset_index().drop('level_1', axis=1).rename(columns={0:'descriptor'})\n",
    "    \n",
    "    #merging metrics and descriptors\n",
    "\n",
    "    master = temp1.merge(temp2, how = 'inner', left_on ='caption', right_on = 'metric_name')[['dashboards','metric_name','descriptor']]\n",
    "    master = master.rename(columns={\"dashboards\":\"dashboard_names\", \"metric_name\": \"metric_names\", \"descriptor\": \"descriptor_names\"})\n",
    "\n",
    "    return master\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\"This is the final dataframe we would be using.\"\n",
    "master = preprocess_datafiles(dfdashboards,dfmetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dashboard_names_list = list(master.dashboard_names.unique())\n",
    "metric_names_list = list(master.metric_names.unique())\n",
    "descriptor_names_list = list(master.descriptor_names.unique())\n",
    "mastercorpus = dashboard_names_list + metric_names_list + descriptor_names_list\n",
    "\n",
    "mastercorpus = list(filter(None,mastercorpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipynb in /Users/ninadmehta/opt/anaconda3/lib/python3.8/site-packages (0.5.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipynb.fs.full.trial2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b96a79a6d3f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# from trial2 import fuzzywuzzy_scorers_suggestions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mipynb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstarts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipynb.fs.full.trial2'"
     ]
    }
   ],
   "source": [
    "# from trial2 import fuzzywuzzy_scorers_suggestions\n",
    "from ipynb.fs.full.trial2 import starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pynput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pynput.keyboard import Listener\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from pynput.keyboard import Key, Listener\n",
    "# s = \"\"\n",
    "# def on_press(key):\n",
    "#     print('aaaaaaaaaaaa',type(str(key)))\n",
    "#     print('{0} pressed'.format(key))\n",
    "#     key = str(key) + str(key)\n",
    "#     print(key)\n",
    "# #     starts(str(key),mastercorpus, master,dashboard_names_list,metric_names_list)\n",
    "# def on_release(key):\n",
    "#     print('{0} release'.format(key))\n",
    "   \n",
    "#     if key == Key.esc:\n",
    "#         # Stop listener\n",
    "#         return False\n",
    "\n",
    "# # Collect events until dreleasedg\n",
    "# with Listener(\n",
    "#         on_press=on_press,\n",
    "#         on_release=on_release) as listener:\n",
    "#     listener.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pynput.keyboard import Listener, Key\n",
    "\n",
    "# filename = \"key_log.txt\"  # The file to write characters to\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "buffer = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def on_press(key):\n",
    "#     f = open(filename, 'a')  # Open the file\n",
    "    global buffer \n",
    "    \n",
    "    if hasattr(key, 'char'):  # Write the character pressed if available\n",
    "        x = (key.char)\n",
    "    elif key == Key.space:  # If space was pressed, write a space\n",
    "        x = (' ')\n",
    "    elif key == Key.enter:  # If enter was pressed, write a new line\n",
    "        pass\n",
    "    elif key == Key.tab:  # If tab was pressed, write a tab\n",
    "        pass\n",
    "    elif key == Key.esc:\n",
    "        # Stop listener\n",
    "        return False\n",
    "    else:  # If anything else was pressed, write [<key_name>]\n",
    "        x = ('[' + key.name + ']')\n",
    "    \n",
    "    buffer += x \n",
    "    \n",
    "    print(type(buffer))\n",
    "    print(buffer)\n",
    "    starts(str(buffer),mastercorpus, master,dashboard_names_list,metric_names_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with Listener(on_press=on_press) as listener:  # Setup the listener\n",
    "    listener.join()  # Join the  thread to the main thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amber ale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
