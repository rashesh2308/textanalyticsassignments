{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling of BBC Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "from string import punctuation\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import LsiModel, LdaModel, CoherenceModel\n",
    "\n",
    "os.chdir(r'/Users/rasheshkothari/Desktop/Text Analytics/Assignment 3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_articles_data = pd.read_csv('BBC-articles.csv')\n",
    "bbc_articles_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Vectorization and Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')\n",
    "articles_list = bbc_articles_data['text'].tolist()\n",
    "\n",
    "# Cleaned the text of punctuations, stopwords and special characters\n",
    "# Lemmatized the words\n",
    "def cleaned_text(text):\n",
    "    text = text.strip(punctuation).lower()\n",
    "    text = re.sub(r'[!?,.\\:;\\n\\t]+', '', text)\n",
    "    \n",
    "    word= nltk.tokenize.word_tokenize(text)\n",
    "    word = [w for w in word if w.isalpha()]\n",
    "    word = [w for w in word if w not in stopwords and len(w) > 2]\n",
    "\n",
    "    wordnet = nltk.stem.WordNetLemmatizer()\n",
    "    lemmatized_words = [wordnet.lemmatize(w) for w in word]\n",
    "    return lemmatized_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After normal cleaning of the text corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(24212 unique tokens: ['abiding', 'according', 'adam', 'added', 'advert']...)\n"
     ]
    }
   ],
   "source": [
    "tokenized_words = []\n",
    "for article in articles_list:\n",
    "    tokenized_words.append(cleaned_text(article))\n",
    "\n",
    "    \n",
    "\n",
    "dictionary1 = Dictionary(tokenized_words)  \n",
    "print(dictionary1)\n",
    "dictionary1.token2id \n",
    "len(dictionary1.token2id)\n",
    "dtm1 = [dictionary1.doc2bow(doc) for doc in tokenized_words]\n",
    "\n",
    "tfidf1 = TfidfModel(dtm1)\n",
    "tfidf1 = tfidf1[dtm1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_model1 = LsiModel(tfidf1, id2word = dictionary1, num_topics = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model1 = LdaModel(tfidf1, id2word = dictionary1, num_topics = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With term frequency filter, to exclude the top 10% of the most frequent words and words that appear less than 5 times in the documents (drawing from Zipf's Law)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary2 = dictionary1\n",
    "\n",
    "# Filtered the extreme words\n",
    "dictionary2.filter_extremes(no_below = 5, no_above = 0.90)\n",
    "dtm2 = [dictionary2.doc2bow(doc) for doc in tokenized_words]\n",
    "tfidf2 = TfidfModel(dtm2)\n",
    "tfidf2 = tfidf2[dtm2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_model2 = LsiModel(tfidf2, id2word = dictionary2, num_topics = 5)\n",
    "lda_model2 = LdaModel(tfidf2, id2word = dictionary2, num_topics = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With a part of speech filter, to limit your TD-IDF matrix to nouns only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_nouns = []\n",
    "\n",
    "# Iterated over a for loop to populate a list of nouns\n",
    "for i in tokenized_words:\n",
    "    words_pos = nltk.pos_tag(i)\n",
    "    list_of_nouns = [w for w, p in words_pos if p == 'NN']\n",
    "    tokenized_nouns.append(list_of_nouns)\n",
    "\n",
    "dictionary3 = Dictionary(tokenized_nouns)\n",
    "\n",
    "dtm3 = [dictionary3.doc2bow(doc) for doc in tokenized_nouns]\n",
    "tfidf3 = TfidfModel(dtm3)\n",
    "tfidf3 = tfidf3[dtm3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_model3 = LsiModel(tfidf3, id2word = dictionary3, num_topics = 5)\n",
    "lda_model3 = LdaModel(tfidf3, id2word = dictionary3, num_topics = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>LSIModelKeywords1</th>\n",
       "      <th>LDAModelKeywords1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "      <td>older, mitsubishi, trial, scooped, affordable</td>\n",
       "      <td>family, position, simple, older, slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "      <td>york, warned, motor, option, vulnerability</td>\n",
       "      <td>family, position, simple, older, slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "      <td>york, warned, motor, option, vulnerability</td>\n",
       "      <td>pig, level, fourth, budget, something</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "      <td>older, trial, york, warned, motor</td>\n",
       "      <td>pig, level, fourth, budget, something</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "      <td>budget, something, pig, fourth, plan</td>\n",
       "      <td>pig, level, fourth, budget, something</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text  \\\n",
       "0           tech  tv future in the hands of viewers with home th...   \n",
       "1       business  worldcom boss  left books alone  former worldc...   \n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...   \n",
       "3          sport  yeading face newcastle in fa cup premiership s...   \n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve...   \n",
       "\n",
       "                               LSIModelKeywords1  \\\n",
       "0  older, mitsubishi, trial, scooped, affordable   \n",
       "1     york, warned, motor, option, vulnerability   \n",
       "2     york, warned, motor, option, vulnerability   \n",
       "3              older, trial, york, warned, motor   \n",
       "4           budget, something, pig, fourth, plan   \n",
       "\n",
       "                       LDAModelKeywords1  \n",
       "0  family, position, simple, older, slow  \n",
       "1  family, position, simple, older, slow  \n",
       "2  pig, level, fourth, budget, something  \n",
       "3  pig, level, fourth, budget, something  \n",
       "4  pig, level, fourth, budget, something  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get most frequent keywords for each article\n",
    "\n",
    "def getMostFrequentKeywords(model, corpus, texts): \n",
    "    topic_keywords_list = []\n",
    "    \n",
    "    # Got the main topic of each document\n",
    "    for i, row in enumerate(model[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        \n",
    "        # Got the frequently used keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  \n",
    "                try:\n",
    "                    word_prop = model.show_topic(topic_num)\n",
    "                    topic_keywords = \", \".join([word for word, prop in word_prop[:5]])\n",
    "                    topic_keywords_list.append(topic_keywords)\n",
    "                except:\n",
    "                    continue\n",
    "            else:\n",
    "                break\n",
    "    return(pd.Series(topic_keywords_list))\n",
    "\n",
    "# Assigned the keywords for each vectorization and model combination\n",
    "bbc_articles_data['LSIModelKeywords1'] = getMostFrequentKeywords(model=lsi_model1, corpus=tfidf1, texts=bbc_articles_data.text)\n",
    "bbc_articles_data['LDAModelKeywords1'] = getMostFrequentKeywords(model=lda_model1, corpus=tfidf1, texts=bbc_articles_data.text)\n",
    "bbc_articles_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_articles_data['LSIModelKeywords2'] = getMostFrequentKeywords(model=lsi_model2, corpus=tfidf2, texts=bbc_articles_data.text)\n",
    "bbc_articles_data['LDAModelKeywords2'] = getMostFrequentKeywords(model=lda_model2, corpus=tfidf2, texts=bbc_articles_data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_articles_data['LSIModelKeywords3'] = getMostFrequentKeywords(model=lsi_model3, corpus=tfidf3, texts=bbc_articles_data.text)\n",
    "bbc_articles_data['LDAModelKeywords3'] = getMostFrequentKeywords(model=lda_model3, corpus=tfidf3, texts=bbc_articles_data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combined all the keywords\n",
    "bbc_articles_data['AllKeywords'] = bbc_articles_data['LSIModelKeywords1'] + ', ' + bbc_articles_data['LSIModelKeywords2'] + ', ' + bbc_articles_data['LSIModelKeywords3'] + ', ' + bbc_articles_data['LDAModelKeywords1'].fillna(method='ffill') + ', ' + bbc_articles_data['LDAModelKeywords2'] + ', ' + bbc_articles_data['LDAModelKeywords3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Top5FreqWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "      <td>phone, mobile, party, blair, game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "      <td>film,york, warned, motor, option</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "      <td>mobile, phone, economy, film, game</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  tv future in the hands of viewers with home th...   \n",
       "1  worldcom boss  left books alone  former worldc...   \n",
       "2  tigers wary of farrell  gamble  leicester say ...   \n",
       "\n",
       "                         Top5FreqWords  \n",
       "0    phone, mobile, party, blair, game  \n",
       "1     film,york, warned, motor, option  \n",
       "2   mobile, phone, economy, film, game  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated 5 most common keywords across the four groups of keywords\n",
    "from collections import Counter \n",
    "for i in bbc_articles_data.index:\n",
    "    keywords = bbc_articles_data.loc[i, 'AllKeywords']\n",
    "    keywords = keywords.split(',')\n",
    "    most_occur = Counter(keywords).most_common(5) \n",
    "    bbc_articles_data.loc[i, 'Top5FreqWords'] = ','.join([word[0] for word in most_occur])\n",
    "\n",
    "bbc_articles_data[['text', 'Top5FreqWords']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>LSIModelKeywords1</th>\n",
       "      <th>LDAModelKeywords1</th>\n",
       "      <th>LSIModelKeywords2</th>\n",
       "      <th>LDAModelKeywords2</th>\n",
       "      <th>LSIModelKeywords3</th>\n",
       "      <th>LDAModelKeywords3</th>\n",
       "      <th>Top5FreqWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "      <td>older, mitsubishi, trial, scooped, affordable</td>\n",
       "      <td>family, position, simple, older, slow</td>\n",
       "      <td>mobile, phone, film, award, best</td>\n",
       "      <td>blair, party, phone, game, mobile</td>\n",
       "      <td>election, tax, party, blair, government</td>\n",
       "      <td>phone, technology, music, software, game</td>\n",
       "      <td>phone, mobile, party, blair, game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "      <td>york, warned, motor, option, vulnerability</td>\n",
       "      <td>family, position, simple, older, slow</td>\n",
       "      <td>mobile, phone, film, award, best</td>\n",
       "      <td>virus, woodward, player, film, lion</td>\n",
       "      <td>election, tax, party, blair, government</td>\n",
       "      <td>film, search, bank, dollar, price</td>\n",
       "      <td>film,york, warned, motor, option</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "      <td>york, warned, motor, option, vulnerability</td>\n",
       "      <td>pig, level, fourth, budget, something</td>\n",
       "      <td>mobile, phone, economy, growth, film</td>\n",
       "      <td>blair, party, phone, game, mobile</td>\n",
       "      <td>film, game, england, award, oscar</td>\n",
       "      <td>blair, sale, tax, party, economy</td>\n",
       "      <td>mobile, phone, economy, film, game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "      <td>older, trial, york, warned, motor</td>\n",
       "      <td>pig, level, fourth, budget, something</td>\n",
       "      <td>mobile, phone, economy, growth, film</td>\n",
       "      <td>blair, party, phone, game, mobile</td>\n",
       "      <td>film, game, england, award, oscar</td>\n",
       "      <td>blog, blair, domain, party, election</td>\n",
       "      <td>mobile, phone, film, game, blair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "      <td>budget, something, pig, fourth, plan</td>\n",
       "      <td>pig, level, fourth, budget, something</td>\n",
       "      <td>film, award, england, best, oscar</td>\n",
       "      <td>blair, party, phone, game, mobile</td>\n",
       "      <td>election, tax, party, blair, government</td>\n",
       "      <td>blair, sale, tax, party, economy</td>\n",
       "      <td>party, blair, something, pig, fourth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text  \\\n",
       "0           tech  tv future in the hands of viewers with home th...   \n",
       "1       business  worldcom boss  left books alone  former worldc...   \n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...   \n",
       "3          sport  yeading face newcastle in fa cup premiership s...   \n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve...   \n",
       "\n",
       "                               LSIModelKeywords1  \\\n",
       "0  older, mitsubishi, trial, scooped, affordable   \n",
       "1     york, warned, motor, option, vulnerability   \n",
       "2     york, warned, motor, option, vulnerability   \n",
       "3              older, trial, york, warned, motor   \n",
       "4           budget, something, pig, fourth, plan   \n",
       "\n",
       "                       LDAModelKeywords1  \\\n",
       "0  family, position, simple, older, slow   \n",
       "1  family, position, simple, older, slow   \n",
       "2  pig, level, fourth, budget, something   \n",
       "3  pig, level, fourth, budget, something   \n",
       "4  pig, level, fourth, budget, something   \n",
       "\n",
       "                      LSIModelKeywords2                    LDAModelKeywords2  \\\n",
       "0      mobile, phone, film, award, best    blair, party, phone, game, mobile   \n",
       "1      mobile, phone, film, award, best  virus, woodward, player, film, lion   \n",
       "2  mobile, phone, economy, growth, film    blair, party, phone, game, mobile   \n",
       "3  mobile, phone, economy, growth, film    blair, party, phone, game, mobile   \n",
       "4     film, award, england, best, oscar    blair, party, phone, game, mobile   \n",
       "\n",
       "                         LSIModelKeywords3  \\\n",
       "0  election, tax, party, blair, government   \n",
       "1  election, tax, party, blair, government   \n",
       "2        film, game, england, award, oscar   \n",
       "3        film, game, england, award, oscar   \n",
       "4  election, tax, party, blair, government   \n",
       "\n",
       "                          LDAModelKeywords3  \\\n",
       "0  phone, technology, music, software, game   \n",
       "1         film, search, bank, dollar, price   \n",
       "2          blair, sale, tax, party, economy   \n",
       "3      blog, blair, domain, party, election   \n",
       "4          blair, sale, tax, party, economy   \n",
       "\n",
       "                           Top5FreqWords  \n",
       "0      phone, mobile, party, blair, game  \n",
       "1       film,york, warned, motor, option  \n",
       "2     mobile, phone, economy, film, game  \n",
       "3       mobile, phone, film, game, blair  \n",
       "4   party, blair, something, pig, fourth  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_articles_data = bbc_articles_data.drop(['AllKeywords'], axis=1)\n",
    "bbc_articles_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exported the populated corpus to a csv\n",
    "bbc_articles_data.to_csv('BBC_News_Keywords.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used 6 different combinations of TF-IDF vectorization techniques using algorithms(LSI and LDA). From the results we can observe that, LDA algorithm with TF-IDF vectorization works better on the dataset as the keywords from the most dominant topic are more relevant and descriptive for each article. \n",
    "\n",
    "Below are the 5 most frequent words in each category\n",
    "LSI with TF-IDF vetorization (normal cleaning): older, mitsubishi, trial, scooped, affordable.\n",
    "Very few keywords are related to technology.\n",
    "\n",
    "LDA with TF-IDF Vectorization (normal cleaning): family, position, simple, older, slow.\n",
    "Few keywords are related to technolgy.\n",
    "\n",
    "LSI with TF-IDF vectorization (term frequency filter): mobile, phone, film, award, best. Very few keywords are related to technology\n",
    "\n",
    "LDA with TF-IDF vectorization (term frequency filter): blair, party, phone, game, mobile. Very few keywords are related to technology.\n",
    "\n",
    "LSI with TF-IDF vectorization (part of speech filter): election, tax, party, blair, government. Very few keywords are related to technology\n",
    "\n",
    "LDA with TF-IDF vectorization (part of speech filter): phone, technology, music, software, game. Very few keywords are related to technology.\n",
    "\n",
    "We can clearly observe that LDA with TF-IDF vetorization in normal cleaning method performs the best amogst all the combinations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
