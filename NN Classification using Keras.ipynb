{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Neural Network Classification - Using Keras\n",
    "\n",
    "https://keras.io\n",
    "\n",
    "INSTALL pip install tensorflow and check (keras is part of tensorflow 2.0\n",
    "(my version is older pip install tensorflow followed by pip install keras)\n",
    "\n",
    "We will predict the ocean proximity (`ocean_proximity` column) of Californian districts, given a number of features from these districts.\n",
    "\n",
    "**The unit of analysis is a DISTRICT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bp/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/bp/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/bp/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/bp/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/bp/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/bp/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = pd.read_csv(\"housing.csv\")\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.570689</td>\n",
       "      <td>35.633221</td>\n",
       "      <td>28.633094</td>\n",
       "      <td>2636.504233</td>\n",
       "      <td>537.870553</td>\n",
       "      <td>1424.946949</td>\n",
       "      <td>499.433465</td>\n",
       "      <td>3.871162</td>\n",
       "      <td>206864.413155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.003578</td>\n",
       "      <td>2.136348</td>\n",
       "      <td>12.591805</td>\n",
       "      <td>2185.269567</td>\n",
       "      <td>421.385070</td>\n",
       "      <td>1133.208490</td>\n",
       "      <td>382.299226</td>\n",
       "      <td>1.899291</td>\n",
       "      <td>115435.667099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.800000</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1450.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.563700</td>\n",
       "      <td>119500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.490000</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.536500</td>\n",
       "      <td>179700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.010000</td>\n",
       "      <td>37.720000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3143.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>1722.000000</td>\n",
       "      <td>604.000000</td>\n",
       "      <td>4.744000</td>\n",
       "      <td>264700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.310000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          longitude      latitude  housing_median_age   total_rooms  \\\n",
       "count  20433.000000  20433.000000        20433.000000  20433.000000   \n",
       "mean    -119.570689     35.633221           28.633094   2636.504233   \n",
       "std        2.003578      2.136348           12.591805   2185.269567   \n",
       "min     -124.350000     32.540000            1.000000      2.000000   \n",
       "25%     -121.800000     33.930000           18.000000   1450.000000   \n",
       "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
       "75%     -118.010000     37.720000           37.000000   3143.000000   \n",
       "max     -114.310000     41.950000           52.000000  39320.000000   \n",
       "\n",
       "       total_bedrooms    population    households  median_income  \\\n",
       "count    20433.000000  20433.000000  20433.000000   20433.000000   \n",
       "mean       537.870553   1424.946949    499.433465       3.871162   \n",
       "std        421.385070   1133.208490    382.299226       1.899291   \n",
       "min          1.000000      3.000000      1.000000       0.499900   \n",
       "25%        296.000000    787.000000    280.000000       2.563700   \n",
       "50%        435.000000   1166.000000    409.000000       3.536500   \n",
       "75%        647.000000   1722.000000    604.000000       4.744000   \n",
       "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
       "\n",
       "       median_house_value  \n",
       "count        20433.000000  \n",
       "mean        206864.413155  \n",
       "std         115435.667099  \n",
       "min          14999.000000  \n",
       "25%         119500.000000  \n",
       "50%         179700.000000  \n",
       "75%         264700.000000  \n",
       "max         500001.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop the missing values\n",
    "housing.dropna(axis=0, inplace=True)\n",
    "\n",
    "# Let's also reset the index\n",
    "housing.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data for Machine Learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set the training and test data sets\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1) # drop labels \n",
    "\n",
    "#Select the label\n",
    "housing_target = housing[[\"ocean_proximity\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "housing_num_std = scaler.fit_transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.32731375,  1.05171726,  0.98216331, ..., -0.97683327,\n",
       "         2.34516291,  2.12881864],\n",
       "       [-1.32232256,  1.04235526, -0.60621017, ...,  1.67037262,\n",
       "         2.33263161,  1.31362603],\n",
       "       [-1.33230494,  1.03767426,  1.85576873, ..., -0.84342665,\n",
       "         1.78293943,  1.25818254],\n",
       "       ...,\n",
       "       [-0.82320322,  1.77727236, -0.92388486, ..., -0.17377773,\n",
       "        -1.14317103, -0.99247676],\n",
       "       [-0.87311515,  1.77727236, -0.84446619, ..., -0.39350628,\n",
       "        -1.05513604, -1.05831591],\n",
       "       [-0.83318561,  1.74918635, -1.00330353, ...,  0.07995643,\n",
       "        -0.78060586, -1.01759959]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_num_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20433, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_num_std.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the label column\n",
    "\n",
    "Tensorflow wants the labels in integer form. So, we need to do Ordinal Encoding, then convert the numbers to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "housing_labels_ord = ordinal_encoder.fit_transform(housing_target)\n",
    "\n",
    "housing_labels_ord[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data type is float. It needs to be integer\n",
    "housing_labels_ord.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert to integer\n",
    "\n",
    "housing_labels_int = housing_labels_ord.astype(int)\n",
    "\n",
    "housing_labels_int.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20433, 1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_labels_int.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(housing_num_std, housing_labels_int, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass classification using Keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(50, input_dim=9, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "\n",
    "#final layer: there has to be 5 nodes with softmax (because we have 5 categories)\n",
    "model.add(Dense(5, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "IF BINARY CLASSIFICATION, change the last layer as follows:\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "sgd = keras.optimizers.SGD(lr=0.05)\n",
    "\n",
    "\n",
    "#You need to use \"categorical_crossentropy\" for mutli-class\n",
    "#but since our target is ordinal, we need to use \"sparse_...\"\n",
    "#if it is binary classification, then use binary_crossentropy\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14303/14303 [==============================] - 0s 18us/step - loss: 1.1889 - accuracy: 0.5263\n",
      "Epoch 2/100\n",
      "14303/14303 [==============================] - 0s 9us/step - loss: 0.8298 - accuracy: 0.7085\n",
      "Epoch 3/100\n",
      "14303/14303 [==============================] - 0s 9us/step - loss: 0.6589 - accuracy: 0.7686\n",
      "Epoch 4/100\n",
      "14303/14303 [==============================] - 0s 9us/step - loss: 0.5840 - accuracy: 0.7880\n",
      "Epoch 5/100\n",
      "14303/14303 [==============================] - 0s 9us/step - loss: 0.5296 - accuracy: 0.7948\n",
      "Epoch 6/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.4776 - accuracy: 0.8077\n",
      "Epoch 7/100\n",
      "14303/14303 [==============================] - 0s 12us/step - loss: 0.4245 - accuracy: 0.8303\n",
      "Epoch 8/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.5096 - accuracy: 0.8186\n",
      "Epoch 9/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.3834 - accuracy: 0.8460\n",
      "Epoch 10/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.3702 - accuracy: 0.8512\n",
      "Epoch 11/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.3619 - accuracy: 0.8519\n",
      "Epoch 12/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.3472 - accuracy: 0.8537\n",
      "Epoch 13/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.3590 - accuracy: 0.8541\n",
      "Epoch 14/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.3318 - accuracy: 0.8611\n",
      "Epoch 15/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.3433 - accuracy: 0.8624\n",
      "Epoch 16/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.3461 - accuracy: 0.8604\n",
      "Epoch 17/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.3135 - accuracy: 0.8695\n",
      "Epoch 18/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.3288 - accuracy: 0.8682\n",
      "Epoch 19/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.3071 - accuracy: 0.8727\n",
      "Epoch 20/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.2986 - accuracy: 0.8777\n",
      "Epoch 21/100\n",
      "14303/14303 [==============================] - 0s 12us/step - loss: 0.2888 - accuracy: 0.8799\n",
      "Epoch 22/100\n",
      "14303/14303 [==============================] - 0s 12us/step - loss: 0.2785 - accuracy: 0.8881\n",
      "Epoch 23/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.2718 - accuracy: 0.8920\n",
      "Epoch 24/100\n",
      "14303/14303 [==============================] - 0s 9us/step - loss: 0.2845 - accuracy: 0.8880\n",
      "Epoch 25/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.2620 - accuracy: 0.8929\n",
      "Epoch 26/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.2679 - accuracy: 0.8906\n",
      "Epoch 27/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.2541 - accuracy: 0.8974\n",
      "Epoch 28/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.2478 - accuracy: 0.9005\n",
      "Epoch 29/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.2417 - accuracy: 0.9005\n",
      "Epoch 30/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.2439 - accuracy: 0.9005\n",
      "Epoch 31/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.2351 - accuracy: 0.9033\n",
      "Epoch 32/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.2394 - accuracy: 0.9032\n",
      "Epoch 33/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.2342 - accuracy: 0.9033\n",
      "Epoch 34/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.2239 - accuracy: 0.9082\n",
      "Epoch 35/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.2305 - accuracy: 0.9044\n",
      "Epoch 36/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.2273 - accuracy: 0.9055\n",
      "Epoch 37/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.3082 - accuracy: 0.8944\n",
      "Epoch 38/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.2277 - accuracy: 0.9068\n",
      "Epoch 39/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.2197 - accuracy: 0.9114\n",
      "Epoch 40/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.2160 - accuracy: 0.9123\n",
      "Epoch 41/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.2224 - accuracy: 0.9100\n",
      "Epoch 42/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.2176 - accuracy: 0.9099\n",
      "Epoch 43/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.2085 - accuracy: 0.9146\n",
      "Epoch 44/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.2054 - accuracy: 0.9146\n",
      "Epoch 45/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.2007 - accuracy: 0.9158\n",
      "Epoch 46/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.2050 - accuracy: 0.9149\n",
      "Epoch 47/100\n",
      "14303/14303 [==============================] - 0s 9us/step - loss: 0.2072 - accuracy: 0.9152\n",
      "Epoch 48/100\n",
      "14303/14303 [==============================] - 0s 9us/step - loss: 0.2019 - accuracy: 0.9167\n",
      "Epoch 49/100\n",
      "14303/14303 [==============================] - 0s 9us/step - loss: 0.1952 - accuracy: 0.9197\n",
      "Epoch 50/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.2236 - accuracy: 0.9109\n",
      "Epoch 51/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.1972 - accuracy: 0.9168\n",
      "Epoch 52/100\n",
      "14303/14303 [==============================] - 0s 9us/step - loss: 0.2024 - accuracy: 0.9158\n",
      "Epoch 53/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.1940 - accuracy: 0.9209\n",
      "Epoch 54/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.1978 - accuracy: 0.9181\n",
      "Epoch 55/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.2031 - accuracy: 0.9154\n",
      "Epoch 56/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.2109 - accuracy: 0.9188\n",
      "Epoch 57/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1844 - accuracy: 0.9251\n",
      "Epoch 58/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1885 - accuracy: 0.9201\n",
      "Epoch 59/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1845 - accuracy: 0.9225\n",
      "Epoch 60/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1871 - accuracy: 0.9217\n",
      "Epoch 61/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1841 - accuracy: 0.9240\n",
      "Epoch 62/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1939 - accuracy: 0.9213\n",
      "Epoch 63/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1908 - accuracy: 0.9202\n",
      "Epoch 64/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1778 - accuracy: 0.9280\n",
      "Epoch 65/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1760 - accuracy: 0.9250\n",
      "Epoch 66/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.2308 - accuracy: 0.9142\n",
      "Epoch 67/100\n",
      "14303/14303 [==============================] - 0s 12us/step - loss: 0.1803 - accuracy: 0.9261\n",
      "Epoch 68/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1778 - accuracy: 0.9260\n",
      "Epoch 69/100\n",
      "14303/14303 [==============================] - 0s 12us/step - loss: 0.1767 - accuracy: 0.9258\n",
      "Epoch 70/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1800 - accuracy: 0.9257\n",
      "Epoch 71/100\n",
      "14303/14303 [==============================] - 0s 12us/step - loss: 0.1825 - accuracy: 0.9228\n",
      "Epoch 72/100\n",
      "14303/14303 [==============================] - 0s 12us/step - loss: 0.1750 - accuracy: 0.9264\n",
      "Epoch 73/100\n",
      "14303/14303 [==============================] - 0s 12us/step - loss: 0.1785 - accuracy: 0.9271\n",
      "Epoch 74/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1698 - accuracy: 0.9303\n",
      "Epoch 75/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.1720 - accuracy: 0.9300\n",
      "Epoch 76/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.1747 - accuracy: 0.9292\n",
      "Epoch 77/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.1672 - accuracy: 0.9320\n",
      "Epoch 78/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.2011 - accuracy: 0.9255\n",
      "Epoch 79/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.1708 - accuracy: 0.9290\n",
      "Epoch 80/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.1666 - accuracy: 0.9304\n",
      "Epoch 81/100\n",
      "14303/14303 [==============================] - 0s 10us/step - loss: 0.1702 - accuracy: 0.9292\n",
      "Epoch 82/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1646 - accuracy: 0.9313\n",
      "Epoch 83/100\n",
      "14303/14303 [==============================] - 0s 12us/step - loss: 0.2035 - accuracy: 0.9265\n",
      "Epoch 84/100\n",
      "14303/14303 [==============================] - 0s 12us/step - loss: 0.1606 - accuracy: 0.9339\n",
      "Epoch 85/100\n",
      "14303/14303 [==============================] - 0s 12us/step - loss: 0.1620 - accuracy: 0.9314\n",
      "Epoch 86/100\n",
      "14303/14303 [==============================] - 0s 12us/step - loss: 0.1622 - accuracy: 0.9352\n",
      "Epoch 87/100\n",
      "14303/14303 [==============================] - 0s 12us/step - loss: 0.1619 - accuracy: 0.9334\n",
      "Epoch 88/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1693 - accuracy: 0.9300\n",
      "Epoch 89/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1685 - accuracy: 0.9304\n",
      "Epoch 90/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1768 - accuracy: 0.9290\n",
      "Epoch 91/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1995 - accuracy: 0.9244\n",
      "Epoch 92/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1612 - accuracy: 0.9338\n",
      "Epoch 93/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.2168 - accuracy: 0.9289\n",
      "Epoch 94/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1686 - accuracy: 0.9330\n",
      "Epoch 95/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1543 - accuracy: 0.9350\n",
      "Epoch 96/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1695 - accuracy: 0.9329\n",
      "Epoch 97/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1627 - accuracy: 0.9355\n",
      "Epoch 98/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1792 - accuracy: 0.9328\n",
      "Epoch 99/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1569 - accuracy: 0.9354\n",
      "Epoch 100/100\n",
      "14303/14303 [==============================] - 0s 11us/step - loss: 0.1682 - accuracy: 0.9325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x138a806a0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "model.fit(train_x, train_y, epochs=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6130/6130 [==============================] - 0s 22us/step\n",
      "\n",
      "accuracy: 84.96%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers, Learning rate, Dropout, Initialization & Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "\n",
    "\n",
    "#Set the learning rate:\n",
    "lr=0.001\n",
    "\n",
    "\n",
    "#Available optimizers:\n",
    "adagrad = keras.optimizers.Adagrad(lr=lr, decay=0.0)\n",
    "sgd = keras.optimizers.SGD(lr=lr, momentum=0.0, decay=0.0, nesterov=False)\n",
    "rmsprop = keras.optimizers.RMSprop(lr=lr, rho=0.9, decay=0.0)\n",
    "adam = keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, decay=0.0, amsgrad=False)\n",
    "nesterov_adam = keras.optimizers.Nadam(lr=lr, beta_1=0.9, beta_2=0.999, schedule_decay=0.004)\n",
    "\n",
    "#Initializations:\n",
    "xavier = keras.initializers.glorot_normal(seed=None)\n",
    "he = keras.initializers.he_normal(seed=None)\n",
    "\n",
    "\n",
    "# Activation functions. Uncomment only one\n",
    "#activation = 'elu' \n",
    "activation = 'relu'\n",
    "#activation = 'tanh'\n",
    "#activation = 'sigmoid'\n",
    "\n",
    "\n",
    "\n",
    "#See the droput layers below:\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(50, input_dim=9, activation=activation, kernel_initializer=xavier))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(25, activation=activation, kernel_initializer=xavier))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(10, activation=activation, kernel_initializer=xavier))\n",
    "\n",
    "#final layer: there has to be 5 nodes with softmax (because we have 5 categories)\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "#Compile\"\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer=nesterov_adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14303/14303 [==============================] - 0s 33us/step - loss: 1.2907 - accuracy: 0.5246\n",
      "Epoch 2/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.8433 - accuracy: 0.6971\n",
      "Epoch 3/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.7321 - accuracy: 0.7328\n",
      "Epoch 4/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.6685 - accuracy: 0.7503\n",
      "Epoch 5/100\n",
      "14303/14303 [==============================] - 0s 17us/step - loss: 0.6188 - accuracy: 0.7621\n",
      "Epoch 6/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.5817 - accuracy: 0.7728\n",
      "Epoch 7/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.5385 - accuracy: 0.7851\n",
      "Epoch 8/100\n",
      "14303/14303 [==============================] - 0s 18us/step - loss: 0.5008 - accuracy: 0.7961\n",
      "Epoch 9/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.4800 - accuracy: 0.8046\n",
      "Epoch 10/100\n",
      "14303/14303 [==============================] - 0s 18us/step - loss: 0.4511 - accuracy: 0.8177\n",
      "Epoch 11/100\n",
      "14303/14303 [==============================] - 0s 18us/step - loss: 0.4356 - accuracy: 0.8243\n",
      "Epoch 12/100\n",
      "14303/14303 [==============================] - 0s 18us/step - loss: 0.4186 - accuracy: 0.8297\n",
      "Epoch 13/100\n",
      "14303/14303 [==============================] - 0s 18us/step - loss: 0.4015 - accuracy: 0.8393\n",
      "Epoch 14/100\n",
      "14303/14303 [==============================] - 0s 18us/step - loss: 0.3924 - accuracy: 0.8402\n",
      "Epoch 15/100\n",
      "14303/14303 [==============================] - 0s 18us/step - loss: 0.3821 - accuracy: 0.8436\n",
      "Epoch 16/100\n",
      "14303/14303 [==============================] - 0s 18us/step - loss: 0.3770 - accuracy: 0.8439\n",
      "Epoch 17/100\n",
      "14303/14303 [==============================] - 0s 17us/step - loss: 0.3706 - accuracy: 0.8500\n",
      "Epoch 18/100\n",
      "14303/14303 [==============================] - 0s 18us/step - loss: 0.3598 - accuracy: 0.8500\n",
      "Epoch 19/100\n",
      "14303/14303 [==============================] - 0s 18us/step - loss: 0.3534 - accuracy: 0.8539\n",
      "Epoch 20/100\n",
      "14303/14303 [==============================] - 0s 18us/step - loss: 0.3485 - accuracy: 0.8554\n",
      "Epoch 21/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.3426 - accuracy: 0.8578\n",
      "Epoch 22/100\n",
      "14303/14303 [==============================] - 0s 17us/step - loss: 0.3356 - accuracy: 0.8626\n",
      "Epoch 23/100\n",
      "14303/14303 [==============================] - 0s 18us/step - loss: 0.3315 - accuracy: 0.8664\n",
      "Epoch 24/100\n",
      "14303/14303 [==============================] - 0s 18us/step - loss: 0.3274 - accuracy: 0.8652\n",
      "Epoch 25/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.3203 - accuracy: 0.8698\n",
      "Epoch 26/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.3151 - accuracy: 0.8714\n",
      "Epoch 27/100\n",
      "14303/14303 [==============================] - 0s 18us/step - loss: 0.2988 - accuracy: 0.8782\n",
      "Epoch 28/100\n",
      "14303/14303 [==============================] - 0s 18us/step - loss: 0.3042 - accuracy: 0.8761\n",
      "Epoch 29/100\n",
      "14303/14303 [==============================] - 0s 17us/step - loss: 0.2965 - accuracy: 0.8786\n",
      "Epoch 30/100\n",
      "14303/14303 [==============================] - 0s 18us/step - loss: 0.2914 - accuracy: 0.8811\n",
      "Epoch 31/100\n",
      "14303/14303 [==============================] - 0s 18us/step - loss: 0.2874 - accuracy: 0.8850\n",
      "Epoch 32/100\n",
      "14303/14303 [==============================] - 0s 18us/step - loss: 0.2833 - accuracy: 0.8858\n",
      "Epoch 33/100\n",
      "14303/14303 [==============================] - 0s 17us/step - loss: 0.2775 - accuracy: 0.8869\n",
      "Epoch 34/100\n",
      "14303/14303 [==============================] - 0s 18us/step - loss: 0.2779 - accuracy: 0.8867\n",
      "Epoch 35/100\n",
      "14303/14303 [==============================] - 0s 17us/step - loss: 0.2749 - accuracy: 0.8916\n",
      "Epoch 36/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2698 - accuracy: 0.8932\n",
      "Epoch 37/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2668 - accuracy: 0.8932\n",
      "Epoch 38/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2748 - accuracy: 0.8874\n",
      "Epoch 39/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2568 - accuracy: 0.8965\n",
      "Epoch 40/100\n",
      "14303/14303 [==============================] - 0s 17us/step - loss: 0.2558 - accuracy: 0.8979\n",
      "Epoch 41/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2523 - accuracy: 0.8989\n",
      "Epoch 42/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2479 - accuracy: 0.8986\n",
      "Epoch 43/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2522 - accuracy: 0.8967\n",
      "Epoch 44/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2515 - accuracy: 0.8993\n",
      "Epoch 45/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2494 - accuracy: 0.8986\n",
      "Epoch 46/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2455 - accuracy: 0.8981\n",
      "Epoch 47/100\n",
      "14303/14303 [==============================] - 0s 17us/step - loss: 0.2402 - accuracy: 0.9012\n",
      "Epoch 48/100\n",
      "14303/14303 [==============================] - 0s 17us/step - loss: 0.2388 - accuracy: 0.9019\n",
      "Epoch 49/100\n",
      "14303/14303 [==============================] - 0s 17us/step - loss: 0.2374 - accuracy: 0.9039\n",
      "Epoch 50/100\n",
      "14303/14303 [==============================] - 0s 17us/step - loss: 0.2534 - accuracy: 0.8972\n",
      "Epoch 51/100\n",
      "14303/14303 [==============================] - 0s 17us/step - loss: 0.2396 - accuracy: 0.9032\n",
      "Epoch 52/100\n",
      "14303/14303 [==============================] - 0s 15us/step - loss: 0.2394 - accuracy: 0.9017\n",
      "Epoch 53/100\n",
      "14303/14303 [==============================] - 0s 15us/step - loss: 0.2317 - accuracy: 0.9057\n",
      "Epoch 54/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2326 - accuracy: 0.9067\n",
      "Epoch 55/100\n",
      "14303/14303 [==============================] - 0s 17us/step - loss: 0.2227 - accuracy: 0.9092\n",
      "Epoch 56/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2310 - accuracy: 0.9080\n",
      "Epoch 57/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2379 - accuracy: 0.9032\n",
      "Epoch 58/100\n",
      "14303/14303 [==============================] - 0s 17us/step - loss: 0.2267 - accuracy: 0.9078\n",
      "Epoch 59/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2270 - accuracy: 0.9099\n",
      "Epoch 60/100\n",
      "14303/14303 [==============================] - 0s 17us/step - loss: 0.2302 - accuracy: 0.9051\n",
      "Epoch 61/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2277 - accuracy: 0.9072\n",
      "Epoch 62/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2362 - accuracy: 0.9047\n",
      "Epoch 63/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2221 - accuracy: 0.9092\n",
      "Epoch 64/100\n",
      "14303/14303 [==============================] - 0s 17us/step - loss: 0.2276 - accuracy: 0.9079\n",
      "Epoch 65/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2245 - accuracy: 0.9085\n",
      "Epoch 66/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2133 - accuracy: 0.9134\n",
      "Epoch 67/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2147 - accuracy: 0.9138\n",
      "Epoch 68/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2262 - accuracy: 0.9055\n",
      "Epoch 69/100\n",
      "14303/14303 [==============================] - 0s 17us/step - loss: 0.2145 - accuracy: 0.9109\n",
      "Epoch 70/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2135 - accuracy: 0.9124\n",
      "Epoch 71/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2189 - accuracy: 0.9106\n",
      "Epoch 72/100\n",
      "14303/14303 [==============================] - 0s 18us/step - loss: 0.2165 - accuracy: 0.9109\n",
      "Epoch 73/100\n",
      "14303/14303 [==============================] - 0s 18us/step - loss: 0.2156 - accuracy: 0.9131\n",
      "Epoch 74/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2128 - accuracy: 0.9121\n",
      "Epoch 75/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2140 - accuracy: 0.9134\n",
      "Epoch 76/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2126 - accuracy: 0.9113\n",
      "Epoch 77/100\n",
      "14303/14303 [==============================] - 0s 17us/step - loss: 0.2107 - accuracy: 0.9126\n",
      "Epoch 78/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2122 - accuracy: 0.9126\n",
      "Epoch 79/100\n",
      "14303/14303 [==============================] - 0s 15us/step - loss: 0.2073 - accuracy: 0.9147\n",
      "Epoch 80/100\n",
      "14303/14303 [==============================] - 0s 17us/step - loss: 0.2048 - accuracy: 0.9158\n",
      "Epoch 81/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2072 - accuracy: 0.9151\n",
      "Epoch 82/100\n",
      "14303/14303 [==============================] - 0s 17us/step - loss: 0.2052 - accuracy: 0.9155\n",
      "Epoch 83/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2088 - accuracy: 0.9156\n",
      "Epoch 84/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2409 - accuracy: 0.9018\n",
      "Epoch 85/100\n",
      "14303/14303 [==============================] - 0s 17us/step - loss: 0.2164 - accuracy: 0.9125\n",
      "Epoch 86/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2069 - accuracy: 0.9161\n",
      "Epoch 87/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.1982 - accuracy: 0.9180\n",
      "Epoch 88/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2008 - accuracy: 0.9167\n",
      "Epoch 89/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2048 - accuracy: 0.9162\n",
      "Epoch 90/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2086 - accuracy: 0.9142\n",
      "Epoch 91/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2001 - accuracy: 0.9189\n",
      "Epoch 92/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.1980 - accuracy: 0.9197\n",
      "Epoch 93/100\n",
      "14303/14303 [==============================] - 0s 15us/step - loss: 0.2116 - accuracy: 0.9155\n",
      "Epoch 94/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2039 - accuracy: 0.9166\n",
      "Epoch 95/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2016 - accuracy: 0.9149\n",
      "Epoch 96/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.1968 - accuracy: 0.9200\n",
      "Epoch 97/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2099 - accuracy: 0.9136\n",
      "Epoch 98/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.2043 - accuracy: 0.9180\n",
      "Epoch 99/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.1975 - accuracy: 0.9188\n",
      "Epoch 100/100\n",
      "14303/14303 [==============================] - 0s 16us/step - loss: 0.1965 - accuracy: 0.9188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x13907ed30>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(train_x, train_y, epochs=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6130/6130 [==============================] - 0s 27us/step\n",
      "\n",
      "accuracy: 93.67%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(test_x, test_y)\n",
    "\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early stopping based on validation results\n",
    "\n",
    "To do this, you need to send the validation data sets to the fit() function and use a callback.\n",
    "\n",
    "EarlyStopping Arguments:\n",
    "\n",
    "**monitor:** quantity to be monitored.<br>\n",
    "**min_delta:** minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.<br>\n",
    "**patience:** number of epochs with no improvement after which training will be stopped.<br>\n",
    "**verbose:** verbosity mode.<br>\n",
    "**mode:** one of {auto, min, max}. In min mode, training will stop when the quantity monitored has stopped decreasing; in max mode it will stop when the quantity monitored has stopped increasing; in auto mode, the direction is automatically inferred from the name of the monitored quantity.<br>\n",
    "**baseline:** Baseline value for the monitored quantity to reach. Training will stop if the model doesn't show improvement over the baseline.<br>\n",
    "**restore_best_weights:** whether to restore model weights from the epoch with the best value of the monitored quantity. If False, the model weights obtained at the last step of training are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14303 samples, validate on 6130 samples\n",
      "Epoch 1/100\n",
      "14303/14303 [==============================] - 0s 19us/step - loss: 0.2004 - accuracy: 0.9169 - val_loss: 0.1527 - val_accuracy: 0.9396\n",
      "Epoch 2/100\n",
      "14303/14303 [==============================] - 0s 19us/step - loss: 0.1973 - accuracy: 0.9199 - val_loss: 0.1496 - val_accuracy: 0.9393\n",
      "Epoch 3/100\n",
      "14303/14303 [==============================] - 0s 19us/step - loss: 0.1945 - accuracy: 0.9209 - val_loss: 0.1467 - val_accuracy: 0.9405\n",
      "Epoch 4/100\n",
      "14303/14303 [==============================] - 0s 19us/step - loss: 0.1952 - accuracy: 0.9210 - val_loss: 0.1510 - val_accuracy: 0.9418\n",
      "Epoch 5/100\n",
      "14303/14303 [==============================] - 0s 19us/step - loss: 0.1956 - accuracy: 0.9199 - val_loss: 0.1515 - val_accuracy: 0.9414\n",
      "Epoch 6/100\n",
      "14303/14303 [==============================] - 0s 19us/step - loss: 0.1937 - accuracy: 0.9179 - val_loss: 0.1607 - val_accuracy: 0.9313\n",
      "Epoch 7/100\n",
      "14303/14303 [==============================] - 0s 19us/step - loss: 0.2037 - accuracy: 0.9162 - val_loss: 0.1711 - val_accuracy: 0.9292\n",
      "Epoch 8/100\n",
      "14303/14303 [==============================] - 0s 20us/step - loss: 0.2111 - accuracy: 0.9162 - val_loss: 0.1560 - val_accuracy: 0.9352\n",
      "Epoch 00008: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x138a47908>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "callback = [earlystop]\n",
    "\n",
    "model.fit(train_x, train_y, validation_data=(test_x, test_y), \n",
    "          epochs=100, batch_size=100, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6130/6130 [==============================] - 0s 15us/step\n",
      "\n",
      "accuracy: 93.52%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_x, test_y)\n",
    "\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
